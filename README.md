# Patent Semantic Search API

## ğŸ“‹ Project Overview

A comprehensive semantic search system for patent documents that retrieves the top 3 most relevant patents based on user queries and provides AI-powered summaries. Built with modern technologies and designed for scalability.

## ğŸ¯ Assignment Requirements

**Business Use Case**: Develop a semantic search feature that retrieves the top 3 most relevant documents based on a query provided by the user. The search will be conducted on the abstract and claims fields of JSON documents, with AI-generated summaries of the retrieved documents.

**Technical Requirements**:
- âœ… REST API with single "search" endpoint accepting query parameter
- âœ… Search top 3 most relevant documents from abstracts and claims fields
- âœ… AI-powered summarization using Groq LLaMA-3
- âœ… Containerized system using docker-compose
- âœ… Horizontal and vertical scaling capabilities
- âœ… JSON document processing (300+ patent documents)

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI       â”‚    â”‚  ChromaDB       â”‚    â”‚  Groq API       â”‚
â”‚   REST API      â”‚â—„â”€â”€â–ºâ”‚  Vector Store   â”‚    â”‚  LLaMA-3        â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load Balancer   â”‚    â”‚ Sentence        â”‚    â”‚ Document        â”‚
â”‚ (nginx)         â”‚    â”‚ Transformers    â”‚    â”‚ Processor       â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Features

### Core Functionality
- **Semantic Search**: Uses sentence-transformers (all-MiniLM-L6-v2) for semantic understanding
- **Vector Database**: ChromaDB for efficient similarity search with persistence
- **AI Summarization**: Groq LLaMA-3-70B for intelligent summaries
- **Patent Processing**: Extracts and cleans abstracts, claims, and descriptions from JSON
- **RESTful API**: FastAPI with automatic OpenAPI documentation

### Scalability Features
- **Horizontal Scaling**: Multiple API replicas with nginx load balancer
- **Vertical Scaling**: Configurable memory and CPU limits
- **Persistent Storage**: Vector database persists between deployments
- **Containerization**: Full Docker support for consistent deployment

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **API Framework** | FastAPI | High-performance async API with automatic docs |
| **Vector Search** | ChromaDB | Persistent vector database for semantic search |
| **Embeddings** | sentence-transformers | Text-to-vector conversion (all-MiniLM-L6-v2) |
| **AI Summarization** | Groq LLaMA-3-70B | Advanced text summarization |
| **Data Processing** | pandas, BeautifulSoup | JSON parsing and HTML cleaning |
| **Load Balancer** | nginx | Request distribution for scaling |
| **Containerization** | Docker + docker-compose | Deployment and orchestration |

## ğŸ“¦ Project Structure

```
assignemnt/
â”œâ”€â”€ app.py                      # Main FastAPI application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ Dockerfile                  # Container configuration
â”œâ”€â”€ docker-compose.yml         # Multi-service orchestration
â”œâ”€â”€ nginx.conf                  # Load balancer configuration
â”œâ”€â”€ README.md                   # Documentation
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ .env                        # Environment variables (not in git)
â”œâ”€â”€ services/                   # Application services
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_preprocessor.py
â”‚   â”œâ”€â”€ search_service.py
â”‚   â””â”€â”€ summarization_service.py
â”œâ”€â”€ patent_jsons_ML Assignment/ # Patent data
â”‚   â””â”€â”€ patent_jsons/          # Individual patent JSON files
â””â”€â”€ vector_db/                  # Persistent vector database (gitignored)

## ğŸ”§ Setup Instructions

### Prerequisites
- Python 3.10+ 
- Docker and docker-compose
- Groq API account with API key

### 1. Environment Setup
```bash
# Clone the repository
git clone <repository-url>
cd assignemnt-opensource

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # macOS/Linux

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration
Create `.env` file with your Groq API credentials:
```env
# Groq API Configuration
GROQ_API_KEY=your_groq_api_key_here

# Database Configuration
CHROMA_PERSIST_DIR=./vector_db
COLLECTION_NAME=patent_documents

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true

# Data Configuration
DATA_PATH=./patent_jsons_ML Assignment/patent_jsons/
```

### 3. Running the Application

#### Option A: Local Development
```bash
python app.py
```

#### Option B: Docker Deployment
```bash
# Single instance
docker-compose up --build

# Scaled deployment (3 API replicas)
docker-compose up --build --scale api=3
```

## ğŸŒ API Endpoints

### Base URL: `http://localhost:8000`

| Endpoint | Method | Description | Parameters |
|----------|--------|-------------|------------|
| `/` | GET | API information | None |
| `/health` | GET | Health check | None |
| `/search` | GET | Semantic search | `query` (string, min 3 chars) |
| `/stats` | GET | Database statistics | None |
| `/docs` | GET | Interactive API docs | None |

### Example Usage

```bash
# Health check
curl http://localhost:8000/health

# Semantic search
curl "http://localhost:8000/search?query=cache%20memory%20optimization"

# API documentation
open http://localhost:8000/docs
```

### Response Format
```json
{
  "query": "cache memory optimization",
  "top_documents": [
    {
      "patent_number": "US-20010011328-A1",
      "title": "SOFTWARE-CONTROLLED CACHE MEMORY COMPARTMENTALIZATION",
      "relevance_score": 0.8945
    },
    {
      "patent_number": "US-5758114-A",
      "title": "CACHE MEMORY SYSTEM AND METHOD",
      "relevance_score": 0.8234
    },
    {
      "patent_number": "US-5940858-A",
      "title": "CACHE MEMORY MANAGEMENT SYSTEM",
      "relevance_score": 0.7891
    }
  ],
  "summary": "The retrieved documents describe various cache memory optimization techniques including software-controlled compartmentalization, memory management systems, and performance enhancement methods. These patents focus on improving cache efficiency through intelligent data placement, prefetching mechanisms, and adaptive management strategies.",
  "processing_time": 2.456
}
```

## âš¡ Performance Metrics

### First Run (Cold Start)
- **Document Processing**: ~5-10 minutes (300+ patents)
- **Embedding Generation**: ~3-5 minutes
- **Vector Database Indexing**: ~1-2 minutes

### Subsequent Runs (Warm Start)
- **Application Startup**: ~10-15 seconds
- **Search Query Response**: ~2-5 seconds
- **AI Summary Generation**: ~3-7 seconds

### Scalability
- **Memory Usage**: ~2-4GB per API instance
- **Concurrent Users**: 100+ with load balancing
- **Database Size**: ~500MB for 300 documents

## ğŸ§ª Testing

### Manual Testing
```bash
# Test different query types
curl "http://localhost:8000/search?query=machine%20learning"
curl "http://localhost:8000/search?query=database%20management"
curl "http://localhost:8000/search?query=wireless%20communication"
curl "http://localhost:8000/search?query=artificial%20intelligence"
```

### Automated Testing
```python
import requests

def test_search_api():
    response = requests.get(
        "http://localhost:8000/search",
        params={"query": "cache memory"}
    )
    assert response.status_code == 200
    data = response.json()
    assert len(data["top_documents"]) == 3
    assert "summary" in data
    assert "processing_time" in data
```

## ğŸš€ Deployment Options

### Local Development
- Single instance on localhost:8000
- Real-time code reload
- Direct access to logs

### Production Deployment
- Multi-instance with load balancing
- nginx proxy on port 80
- Persistent data volumes
- Resource limits and monitoring

### Cloud Deployment
- Compatible with AWS, Azure, GCP
- Kubernetes deployment ready
- Auto-scaling capabilities
- Health checks included

## ğŸ“Š Assignment Deliverables

âœ… **Functional Requirements**
- [x] Single REST API endpoint (/search)
- [x] Query parameter acceptance
- [x] Top 3 document retrieval
- [x] Abstract and claims field search
- [x] AI-powered summarization using Groq
- [x] JSON document processing (300+ patents)

âœ… **Technical Requirements**
- [x] Containerized with docker-compose
- [x] Horizontal scaling (multiple API replicas)
- [x] Vertical scaling (resource limits)
- [x] Modern technology stack
- [x] Comprehensive documentation

âœ… **Quality Attributes**
- [x] High performance semantic search
- [x] Scalable architecture design
- [x] Production-ready deployment
- [x] Comprehensive error handling
- [x] Interactive API documentation

## ğŸ” Key Technical Features

### 1. **Semantic Search Engine**
- Uses `all-MiniLM-L6-v2` model for embeddings
- Cosine similarity for document ranking
- Efficient vector search with ChromaDB

### 2. **Document Processing**
- HTML content cleaning with BeautifulSoup
- Patent data extraction from JSON structure
- Text normalization and preprocessing

### 3. **AI Summarization**
- Groq LLaMA-3-70B model for summaries
- Context-aware summarization
- Fallback to extractive summarization

### 4. **Scalable Architecture**
- Microservices design pattern
- Load balancing with nginx
- Persistent vector database storage

## ğŸ† Key Achievements

1. **Advanced Semantic Search**: Implements state-of-the-art sentence transformers
2. **Production-Ready**: Full containerization and scaling capabilities
3. **AI Integration**: Advanced Groq LLaMA-3 integration for superior summaries
4. **Performance Optimized**: Efficient vector database with persistence
5. **Developer Experience**: Interactive API docs and comprehensive testing

## ğŸ“ˆ Future Enhancements

- [ ] Advanced search filters and ranking
- [ ] Real-time document updates
- [ ] Multi-language support
- [ ] Advanced analytics dashboard
- [ ] Federated search across multiple databases
- [ ] Caching layer for improved performance
- [ ] User authentication and rate limiting

## ğŸ› Troubleshooting

### Common Issues

1. **Vector Database Not Found**
   ```bash
   # Delete and recreate vector database
   rm -rf vector_db/
   python app.py
   ```

2. **Groq API Errors**
   ```bash
   # Check API key in .env file
   echo $GROQ_API_KEY
   ```

3. **Docker Build Issues**
   ```bash
   # Clean Docker cache
   docker system prune -a
   docker-compose up --build
   ```

### Logs and Debugging
```bash
# View application logs
docker-compose logs api

# View nginx logs
docker-compose logs nginx

# Check database status
curl http://localhost:8000/stats
```

## ğŸ“š Additional Resources

- **FastAPI Documentation**: https://fastapi.tiangolo.com/
- **ChromaDB Documentation**: https://docs.trychroma.com/
- **Groq API Documentation**: https://console.groq.com/docs
- **Sentence Transformers**: https://www.sbert.net/

---

**Assignment Submission**: This project demonstrates a complete implementation of the semantic search requirements with additional production-ready features and comprehensive documentation. The system successfully processes 300+ patent documents and provides intelligent search capabilities with AI-powered summarization. 